{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNN6ZDkdcdmCbgaLyWUyJUg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6f222dd520f3477e860dd200a27f9d02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37720df50c0a4345a32d214e8c037f1c",
              "IPY_MODEL_525745d8104e4bec83c6fd5f4c0ae912",
              "IPY_MODEL_230f117fb49543dbabc874d2cb868d32"
            ],
            "layout": "IPY_MODEL_319a02d3815d462a933140ededcd1d31"
          }
        },
        "37720df50c0a4345a32d214e8c037f1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7faa26b1ec50461789f371749d22a5a6",
            "placeholder": "​",
            "style": "IPY_MODEL_756268e8468d4cc2b88309512f2ac5f3",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "525745d8104e4bec83c6fd5f4c0ae912": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_738888a2bb5b443fbc905472feab4227",
            "max": 2324,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c9c907e5bb3c4315834b7fa3cab9d8e8",
            "value": 2324
          }
        },
        "230f117fb49543dbabc874d2cb868d32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24c6f9f25c364cd1b74cfac9d590829c",
            "placeholder": "​",
            "style": "IPY_MODEL_c4d55866c7db4aa28c97f71d07884f96",
            "value": " 2.32k/2.32k [00:00&lt;00:00, 284kB/s]"
          }
        },
        "319a02d3815d462a933140ededcd1d31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7faa26b1ec50461789f371749d22a5a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "756268e8468d4cc2b88309512f2ac5f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "738888a2bb5b443fbc905472feab4227": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9c907e5bb3c4315834b7fa3cab9d8e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "24c6f9f25c364cd1b74cfac9d590829c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4d55866c7db4aa28c97f71d07884f96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49c87a1688dd46439880e95d43ca322c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_29eb95f6f63d4052af0906b3ad051eb9",
              "IPY_MODEL_5f85ad05b95e457b8486c3adee7e9340",
              "IPY_MODEL_de41f74d96cb455dbf9f18e65a3f9cfb"
            ],
            "layout": "IPY_MODEL_b8043635c58e4e12b38155e353b201a1"
          }
        },
        "29eb95f6f63d4052af0906b3ad051eb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72397cfc835343af9d286ab3d027abc3",
            "placeholder": "​",
            "style": "IPY_MODEL_f9e61834274640d5844cf46decdc4bf7",
            "value": "spiece.model: 100%"
          }
        },
        "5f85ad05b95e457b8486c3adee7e9340": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02aa1f1e52444cb295a1d7ff93ceb11a",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7382512592c24f07b058ab27f1aba66b",
            "value": 791656
          }
        },
        "de41f74d96cb455dbf9f18e65a3f9cfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cd0af1a0b354ce3b8079890f8c528e3",
            "placeholder": "​",
            "style": "IPY_MODEL_b36f2500bf904351b78bb87b987e55cd",
            "value": " 792k/792k [00:00&lt;00:00, 10.4MB/s]"
          }
        },
        "b8043635c58e4e12b38155e353b201a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72397cfc835343af9d286ab3d027abc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9e61834274640d5844cf46decdc4bf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02aa1f1e52444cb295a1d7ff93ceb11a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7382512592c24f07b058ab27f1aba66b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7cd0af1a0b354ce3b8079890f8c528e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b36f2500bf904351b78bb87b987e55cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "656ec4f582794c74a193c794d01e551e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e82bc74c2274b2e94b501dd4a3a769b",
              "IPY_MODEL_67ea9ab32b974404a103db6c9dba81f7",
              "IPY_MODEL_9659e596a06348b89ccff9b60c69ad51"
            ],
            "layout": "IPY_MODEL_3f328fb7d053420d856fa922a971c181"
          }
        },
        "6e82bc74c2274b2e94b501dd4a3a769b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd2fed86acd74711be3c6e08be0aa43a",
            "placeholder": "​",
            "style": "IPY_MODEL_119fd8ebbc2b4db0811f2bd956571893",
            "value": "tokenizer.json: 100%"
          }
        },
        "67ea9ab32b974404a103db6c9dba81f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_087dae609055448dbb7011bb1166d431",
            "max": 1389353,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e4ce596e653a4fa69da08b5535217a1a",
            "value": 1389353
          }
        },
        "9659e596a06348b89ccff9b60c69ad51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e02970339d484862acd28cdb653f1262",
            "placeholder": "​",
            "style": "IPY_MODEL_125083629b22437fae790b33184393bf",
            "value": " 1.39M/1.39M [00:00&lt;00:00, 6.35MB/s]"
          }
        },
        "3f328fb7d053420d856fa922a971c181": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd2fed86acd74711be3c6e08be0aa43a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "119fd8ebbc2b4db0811f2bd956571893": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "087dae609055448dbb7011bb1166d431": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4ce596e653a4fa69da08b5535217a1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e02970339d484862acd28cdb653f1262": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "125083629b22437fae790b33184393bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ktanguy/University_chatbot_assistant/blob/main/University_chatbot_assistant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lD4rCb7_xaK",
        "outputId": "ff29f02a-114f-45a4-d465-16a4e6bc0f39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/1.8 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  DEPRECATION: Building 'rouge-score' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'rouge-score'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
            "\u001b[0m  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "tensorstore 0.1.77 requires ml_dtypes>=0.5.0, but you have ml-dtypes 0.3.2 which is incompatible.\n",
            "tensorflow-text 2.19.0 requires tensorflow<2.20,>=2.19.0, but you have tensorflow 2.16.1 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.6.1 which is incompatible.\n",
            "tsfresh 0.21.1 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
            "tensorflow-decision-forests 1.12.0 requires tensorflow==2.19.0, but you have tensorflow 2.16.1 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "tf-keras 2.19.0 requires tensorflow<2.20,>=2.19, but you have tensorflow 2.16.1 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "opentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 4.25.8 which is incompatible.\n",
            "jax 0.5.3 requires ml_dtypes>=0.4.0, but you have ml-dtypes 0.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "Environment ready. The runtime will now restart to apply changes...\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# Cell 1 — Environment Setup (Run FIRST)\n",
        "# --------------------------------------------\n",
        "# What this does:\n",
        "# 1) Upgrades pip (the Python package manager).\n",
        "# 2) Installs a known-good, compatible set of libraries:\n",
        "#    - numpy / pandas / scipy (matching binary versions)\n",
        "#    - tensorflow (we'll use TF with Hugging Face)\n",
        "#    - transformers, datasets, evaluate (Hugging Face stack)\n",
        "#    - nltk, rouge-score (text preprocessing + evaluation)\n",
        "# 3) Force a runtime RESTART so Colab reloads C-extensions\n",
        "#    against the just-installed NumPy. This prevents\n",
        "#    the \"numpy.dtype size changed\" error.\n",
        "#\n",
        "# After the restart:\n",
        "#   -> Run your next cell to MOUNT Google Drive.\n",
        "#   -> Then continue with loading your dataset, etc.\n",
        "# ============================================\n",
        "\n",
        "# (Optional) Make TensorFlow logs less noisy\n",
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "\n",
        "# 1) Upgrade pip so installs are smooth\n",
        "!pip -q install --upgrade pip\n",
        "\n",
        "# 2) Install a compatible set of packages\n",
        "#    These versions play nicely together in Colab.\n",
        "!pip -q install \\\n",
        "  \"numpy==1.26.4\" \\\n",
        "  \"pandas==2.2.2\" \\\n",
        "  \"scipy==1.13.1\" \\\n",
        "  \"tensorflow==2.16.1\" \\\n",
        "  \"transformers==4.44.2\" \\\n",
        "  \"datasets==2.21.0\" \\\n",
        "  \"evaluate==0.4.2\" \\\n",
        "  \"nltk==3.9.1\" \\\n",
        "  \"rouge-score==0.1.2\"\n",
        "\n",
        "# 3) RESTART the runtime so Python reloads binary extensions\n",
        "import time, sys\n",
        "print(\"\\nEnvironment ready. The runtime will now restart to apply changes...\")\n",
        "time.sleep(1)\n",
        "\n",
        "# This kills the current Python process; Colab auto-reconnects.\n",
        "import os\n",
        "os.kill(os.getpid(), 9)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1tFZraRAJny",
        "outputId": "7a4c764f-7f96-4d17-8af9-5443c37aeac5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json, os\n",
        "\n",
        "\n",
        "DATASET_PATH = \"/content/drive/MyDrive/UniversityChatbot/intents.json\"\n",
        "\n",
        "assert os.path.exists(DATASET_PATH), f\"File not found at: {DATASET_PATH}\"\n",
        "\n",
        "with open(DATASET_PATH, \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "\n",
        "print(\" Loaded JSON with keys:\", list(data.keys()))\n",
        "print(\"Number of intents:\", len(data.get(\"intents\", [])))\n",
        "print(\"First intent example:\")\n",
        "print(json.dumps(data[\"intents\"][0], indent=2)[:800])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSETuMiYAV55",
        "outputId": "420b89ae-4147-4c20-f78b-ee79062648cc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Loaded JSON with keys: ['intents']\n",
            "Number of intents: 39\n",
            "First intent example:\n",
            "{\n",
            "  \"intent\": \"greeting\",\n",
            "  \"text\": [\n",
            "    \"Hi\",\n",
            "    \"How are you?\",\n",
            "    \"Is anyone there?\",\n",
            "    \"Hello\",\n",
            "    \"Good day\",\n",
            "    \"What's up\",\n",
            "    \"how are ya\",\n",
            "    \"heyy\",\n",
            "    \"whatsup\",\n",
            "    \"??? ??? ??\"\n",
            "  ],\n",
            "  \"responses\": [\n",
            "    \"Hello!\",\n",
            "    \"Good to see you again!\",\n",
            "    \"Hi there, how can I help?\"\n",
            "  ],\n",
            "  \"extension\": {\n",
            "    \"function\": \"\",\n",
            "    \"entities\": false,\n",
            "    \"responses\": []\n",
            "  },\n",
            "  \"context\": {\n",
            "    \"in\": \"\",\n",
            "    \"out\": \"GreetingUserRequest\",\n",
            "    \"clear\": false\n",
            "  },\n",
            "  \"entityType\": \"NA\",\n",
            "  \"entities\": []\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# SAFE TRAIN/VAL/TEST SPLIT + T5 PAIRS (BEGINNER-FRIENDLY)\n",
        "# Expects: df with columns [\"intent\", \"text\", \"response\"]\n",
        "# =========================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ---------- 0) Sanity checks & light cleaning ----------\n",
        "# If the loader cell created different column names, normalize them here.\n",
        "expected_cols = {\"intent\", \"text\", \"response\"}\n",
        "if not expected_cols.issubset(df.columns):\n",
        "    # Try to auto-fix common naming issues (case / spaces)\n",
        "    rename_map = {}\n",
        "    for col in df.columns:\n",
        "        c = col.strip().lower()\n",
        "        if c in [\"intent\", \"tag\"]:  rename_map[col] = \"intent\"\n",
        "        elif c in [\"pattern\", \"patterns\", \"question\", \"query\", \"text\"]: rename_map[col] = \"text\"\n",
        "        elif c in [\"answer\", \"answers\", \"response\", \"responses\", \"reply\"]: rename_map[col] = \"response\"\n",
        "    df = df.rename(columns=rename_map)\n",
        "\n",
        "# Validate again\n",
        "missing = expected_cols - set(df.columns)\n",
        "assert not missing, f\"Your dataframe is missing columns: {missing}. Found columns: {list(df.columns)}\"\n",
        "\n",
        "# Drop rows with missing fields and strip whitespace\n",
        "df = df.dropna(subset=[\"intent\", \"text\", \"response\"]).copy()\n",
        "df[\"intent\"]   = df[\"intent\"].astype(str).str.strip()\n",
        "df[\"text\"]     = df[\"text\"].astype(str).str.strip()\n",
        "df[\"response\"] = df[\"response\"].astype(str).str.strip()\n",
        "\n",
        "# Remove empty texts/responses (just in case)\n",
        "df = df[(df[\"text\"] != \"\") & (df[\"response\"] != \"\")].reset_index(drop=True)\n",
        "\n",
        "print(f\"Data after cleaning: {len(df)} pairs\")\n",
        "print(df.head(3))\n",
        "\n",
        "# ---------- 1) Handle rare intents to avoid stratify errors ----------\n",
        "counts = df[\"intent\"].value_counts()\n",
        "RARE_MIN = 3  # intents with <3 examples go entirely to TRAIN\n",
        "rare_mask = df[\"intent\"].map(counts) < RARE_MIN\n",
        "rare_df   = df[rare_mask].copy()\n",
        "common_df = df[~rare_mask].copy()\n",
        "\n",
        "print(\"\\nSummary of intent frequencies:\")\n",
        "print(counts.head(10))\n",
        "print(f\"\\nTotal pairs: {len(df)} | Rare (<{RARE_MIN}) kept in TRAIN: {len(rare_df)} | Common: {len(common_df)}\")\n",
        "\n",
        "# ---------- 2) Split common intents only (so stratify works) ----------\n",
        "def safe_stratified_split(frame, test_size, desc):\n",
        "    \"\"\"Try a stratified split; if it fails, fall back to a plain split.\"\"\"\n",
        "    if len(frame) == 0:\n",
        "        return frame.copy(), frame.copy()\n",
        "    try:\n",
        "        left, right = train_test_split(\n",
        "            frame,\n",
        "            test_size=test_size,\n",
        "            random_state=42,\n",
        "            shuffle=True,\n",
        "            stratify=frame[\"intent\"]\n",
        "        )\n",
        "        return left, right\n",
        "    except Exception as e:\n",
        "        print(f\"[{desc}] Stratified split failed ({type(e).__name__}: {e}). Falling back to non-stratified split.\")\n",
        "        left, right = train_test_split(\n",
        "            frame,\n",
        "            test_size=test_size,\n",
        "            random_state=42,\n",
        "            shuffle=True\n",
        "        )\n",
        "        return left, right\n",
        "\n",
        "# 20% test from common\n",
        "train_common, test_common = safe_stratified_split(common_df, test_size=0.20, desc=\"COMMON->TEST\")\n",
        "\n",
        "# From the remaining common train, carve ~10% of the original as VAL (≈12.5% of the remaining 80%)\n",
        "val_size_rel = 0.125 if len(train_common) > 0 else 0.0\n",
        "if val_size_rel > 0:\n",
        "    train_common, val_common = safe_stratified_split(train_common, test_size=val_size_rel, desc=\"TRAIN_COMMON->VAL\")\n",
        "else:\n",
        "    val_common = pd.DataFrame(columns=train_common.columns if len(train_common)>0 else common_df.columns)\n",
        "\n",
        "# ---------- 3) Add all rare examples to TRAIN ----------\n",
        "train_df = pd.concat([train_common, rare_df], ignore_index=True)\n",
        "val_df   = val_common.reset_index(drop=True)\n",
        "test_df  = test_common.reset_index(drop=True)\n",
        "\n",
        "# Shuffle train for good measure\n",
        "train_df = train_df.sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# ---------- 4) Report split stats ----------\n",
        "def report_split(name, frame):\n",
        "    print(f\"\\n{name} shape: {frame.shape}\")\n",
        "    if len(frame):\n",
        "        print(frame[\"intent\"].value_counts().head(15))\n",
        "\n",
        "report_split(\"TRAIN\", train_df)\n",
        "report_split(\"VAL\",   val_df)\n",
        "report_split(\"TEST\",  test_df)\n",
        "\n",
        "print(\"\\nNote:\")\n",
        "print(f\"- Intents with < {RARE_MIN} total examples were kept entirely in TRAIN to avoid stratification errors.\")\n",
        "print(\"- Some very-rare intents may not appear in VAL/TEST — document this in your report.\")\n",
        "\n",
        "# ---------- 5) Build T5-style (input_text, target_text) columns ----------\n",
        "def to_t5_pair(row):\n",
        "    # You can tweak this prompt later; keep it simple while training.\n",
        "    return pd.Series({\n",
        "        \"input_text\":  f\"domain: university | intent: {row['intent']} | user: {row['text']}\",\n",
        "        \"target_text\": row[\"response\"]\n",
        "    })\n",
        "\n",
        "train_pairs = train_df.apply(to_t5_pair, axis=1)\n",
        "val_pairs   = val_df.apply(to_t5_pair,   axis=1)\n",
        "test_pairs  = test_df.apply(to_t5_pair,  axis=1)\n",
        "\n",
        "train_df_proc = pd.concat([train_df.reset_index(drop=True), train_pairs], axis=1)\n",
        "val_df_proc   = pd.concat([val_df.reset_index(drop=True),   val_pairs],   axis=1)\n",
        "test_df_proc  = pd.concat([test_df.reset_index(drop=True),  test_pairs],  axis=1)\n",
        "\n",
        "# Final sanity check\n",
        "for name, frame in [(\"train_df_proc\", train_df_proc), (\"val_df_proc\", val_df_proc), (\"test_df_proc\", test_df_proc)]:\n",
        "    assert {\"input_text\",\"target_text\"}.issubset(frame.columns), f\"{name} is missing required columns\"\n",
        "print(\"\\nPrepared T5 pairs. Example rows:\")\n",
        "print(train_df_proc[[\"input_text\",\"target_text\"]].head(3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "qGgz3kHvrRLz",
        "outputId": "4dbd4b38-c495-44b4-e05b-9ddd6b69a5f7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "Your dataframe is missing columns: {'text', 'intent', 'response'}. Found columns: []",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-970125018.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Validate again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpected_cols\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Your dataframe is missing columns: {missing}. Found columns: {list(df.columns)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Drop rows with missing fields and strip whitespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Your dataframe is missing columns: {'text', 'intent', 'response'}. Found columns: []"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "pairs = []\n",
        "for intent in data.get(\"intents\", []):\n",
        "    tag = intent.get(\"tag\", \"unknown\")\n",
        "    patterns = intent.get(\"patterns\", [])\n",
        "    responses = intent.get(\"responses\", [])\n",
        "    if not patterns or not responses:\n",
        "        continue\n",
        "\n",
        "\n",
        "    for p in patterns:\n",
        "        target = responses[0]\n",
        "        pairs.append({\n",
        "            \"tag\": tag,\n",
        "            \"input_text\": f\"question: {p.strip()}\",\n",
        "            \"target_text\": target.strip()\n",
        "        })\n",
        "\n",
        "df = pd.DataFrame(pairs)\n",
        "print(\"Total pairs:\", len(df))\n",
        "df.head(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "lSFmgRxHBudY",
        "outputId": "940ba050-84cc-495d-ec83-330dcd06ccb5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total pairs: 0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: []\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-399d63a6-de4c-4cb9-b8d5-a79ccce5b5cb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-399d63a6-de4c-4cb9-b8d5-a79ccce5b5cb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-399d63a6-de4c-4cb9-b8d5-a79ccce5b5cb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-399d63a6-de4c-4cb9-b8d5-a79ccce5b5cb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 0,\n  \"fields\": []\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Robust, stratified train/val/test split with rare-intent handling\n",
        "# =========================\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# df must already exist with columns: [\"intent\", \"text\", \"response\"]\n",
        "\n",
        "# 1) Count how many examples per intent\n",
        "counts = df[\"intent\"].value_counts()\n",
        "\n",
        "# 2) Define \"rare\" intents: fewer than 3 examples total\n",
        "#    We keep all rare examples in TRAIN to avoid stratification errors.\n",
        "RARE_MIN = 3\n",
        "rare_mask   = df[\"intent\"].map(counts) < RARE_MIN\n",
        "rare_df     = df[rare_mask].copy()\n",
        "common_df   = df[~rare_mask].copy()\n",
        "\n",
        "print(f\"Total pairs: {len(df)} | Rare pairs (kept in train only): {len(rare_df)} | Common pairs: {len(common_df)}\")\n",
        "print(\"\\nRare intents (kept in train only):\")\n",
        "print(df.loc[rare_mask, \"intent\"].value_counts())\n",
        "\n",
        "# 3) Stratified split on common intents (those with >= RARE_MIN)\n",
        "#    First: common -> train_common + test (20% test)\n",
        "if len(common_df[\"intent\"].unique()) > 1:\n",
        "    train_common, test_common = train_test_split(\n",
        "        common_df,\n",
        "        test_size=0.20,\n",
        "        random_state=42,\n",
        "        shuffle=True,\n",
        "        stratify=common_df[\"intent\"]\n",
        "    )\n",
        "else:\n",
        "    # Fallback if somehow only one common intent remains\n",
        "    train_common, test_common = common_df, pd.DataFrame(columns=common_df.columns)\n",
        "\n",
        "# 4) From train_common, carve out a validation set (~10% of total)\n",
        "#    Since we already took 20% test, taking 12.5% of train_common ≈ 10% of original common\n",
        "if len(train_common) > 0 and len(train_common[\"intent\"].unique()) > 1:\n",
        "    train_common, val_common = train_test_split(\n",
        "        train_common,\n",
        "        test_size=0.125,  # 12.5% of the remaining 80% ≈ 10% overall\n",
        "        random_state=42,\n",
        "        shuffle=True,\n",
        "        stratify=train_common[\"intent\"]\n",
        "    )\n",
        "else:\n",
        "    val_common = pd.DataFrame(columns=train_common.columns)\n",
        "\n",
        "# 5) Add all rare samples to TRAIN\n",
        "train_df = pd.concat([train_common, rare_df], ignore_index=True)\n",
        "val_df   = val_common.reset_index(drop=True)\n",
        "test_df  = test_common.reset_index(drop=True)\n",
        "\n",
        "# 6) Shuffle train for good measure\n",
        "train_df = train_df.sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# 7) Report splits and intent coverage\n",
        "def counts_by_split(name, frame):\n",
        "    print(f\"\\n{name} shape: {frame.shape}\")\n",
        "    print(frame[\"intent\"].value_counts())\n",
        "\n",
        "counts_by_split(\"TRAIN\", train_df)\n",
        "counts_by_split(\"VAL\",   val_df)\n",
        "counts_by_split(\"TEST\",  test_df)\n",
        "\n",
        "print(\"\\nNote:\")\n",
        "print(\"- Intents with < 3 total examples were kept entirely in TRAIN to avoid stratification errors.\")\n",
        "print(\"- This means some very-rare intents may not appear in VAL/TEST (that’s okay; document this in your report).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "SDZ-AvKiEA8u",
        "outputId": "64412dda-1a17-4760-c096-20ea91518fd6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'intent'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2548991535.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# 1) Count how many examples per intent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"intent\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# 2) Define \"rare\" intents: fewer than 3 examples total\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHashable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_indexing_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'intent'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# Build seq2seq fields for T5 fine-tuning\n",
        "# =========================================\n",
        "\n",
        "def build_io(df):\n",
        "    df = df.copy()\n",
        "    # A simple, informative prompt template for T5\n",
        "    # You can remove `intent:` if you want pure text-to-text, but keeping it helps conditioning.\n",
        "    df[\"input_text\"]  = \"intent: \" + df[\"intent\"].astype(str) + \" | user: \" + df[\"text\"].astype(str)\n",
        "    df[\"target_text\"] = df[\"response\"].astype(str)\n",
        "    return df\n",
        "\n",
        "train_df_io = build_io(train_df)\n",
        "val_df_io   = build_io(val_df)\n",
        "test_df_io  = build_io(test_df)\n",
        "\n",
        "# Sanity check\n",
        "print(train_df_io[[\"intent\",\"text\",\"response\",\"input_text\",\"target_text\"]].head(3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "PvidYBGPiJaf",
        "outputId": "551517ad-0011-4aba-ac57-f44ff18b1e97"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1417220057.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtrain_df_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_io\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mval_df_io\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mbuild_io\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mtest_df_io\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mbuild_io\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== CELL 5: Tokenize inputs/targets for T5-small (TensorFlow) ====\n",
        "from transformers import AutoTokenizer\n",
        "import numpy as np\n",
        "\n",
        "MODEL_NAME = \"t5-small\"   # small and fast; good for seq2seq\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# Set some safe max lengths (adjust if your texts are long)\n",
        "MAX_INPUT_LEN  = 64\n",
        "MAX_TARGET_LEN = 64\n",
        "\n",
        "def tokenize_pairs(df_slice):\n",
        "    \"\"\"\n",
        "    Convert a pandas slice with columns 'input_text', 'target_text'\n",
        "    into (input_ids, attention_mask, labels) numpy arrays padded\n",
        "    to fixed lengths so we can use tf.data easily.\n",
        "    \"\"\"\n",
        "    enc_inputs = tokenizer(\n",
        "        df_slice[\"input_text\"].tolist(),\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=MAX_INPUT_LEN,\n",
        "        return_tensors=\"np\"\n",
        "    )\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        enc_targets = tokenizer(\n",
        "            df_slice[\"target_text\"].tolist(),\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=MAX_TARGET_LEN,\n",
        "            return_tensors=\"np\"\n",
        "        )\n",
        "\n",
        "    # Important: For seq2seq training in TF, labels should be -100 for padded tokens\n",
        "    labels = enc_targets[\"input_ids\"].copy()\n",
        "    labels[labels == tokenizer.pad_token_id] = -100\n",
        "\n",
        "    return enc_inputs[\"input_ids\"], enc_inputs[\"attention_mask\"], labels\n",
        "\n",
        "Xtr_ids, Xtr_mask, ytr = tokenize_pairs(train_df)\n",
        "Xv_ids,  Xv_mask,  yv  = tokenize_pairs(val_df)\n",
        "Xt_ids,  Xt_mask,  yt  = tokenize_pairs(test_df)\n",
        "\n",
        "print(\"Train shapes:\", Xtr_ids.shape, Xtr_mask.shape, ytr.shape)\n",
        "print(\"Val shapes:\",   Xv_ids.shape,  Xv_mask.shape,  yv.shape)\n",
        "print(\"Test shapes:\",  Xt_ids.shape,  Xt_mask.shape,  yt.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411,
          "referenced_widgets": [
            "6f222dd520f3477e860dd200a27f9d02",
            "37720df50c0a4345a32d214e8c037f1c",
            "525745d8104e4bec83c6fd5f4c0ae912",
            "230f117fb49543dbabc874d2cb868d32",
            "319a02d3815d462a933140ededcd1d31",
            "7faa26b1ec50461789f371749d22a5a6",
            "756268e8468d4cc2b88309512f2ac5f3",
            "738888a2bb5b443fbc905472feab4227",
            "c9c907e5bb3c4315834b7fa3cab9d8e8",
            "24c6f9f25c364cd1b74cfac9d590829c",
            "c4d55866c7db4aa28c97f71d07884f96",
            "49c87a1688dd46439880e95d43ca322c",
            "29eb95f6f63d4052af0906b3ad051eb9",
            "5f85ad05b95e457b8486c3adee7e9340",
            "de41f74d96cb455dbf9f18e65a3f9cfb",
            "b8043635c58e4e12b38155e353b201a1",
            "72397cfc835343af9d286ab3d027abc3",
            "f9e61834274640d5844cf46decdc4bf7",
            "02aa1f1e52444cb295a1d7ff93ceb11a",
            "7382512592c24f07b058ab27f1aba66b",
            "7cd0af1a0b354ce3b8079890f8c528e3",
            "b36f2500bf904351b78bb87b987e55cd",
            "656ec4f582794c74a193c794d01e551e",
            "6e82bc74c2274b2e94b501dd4a3a769b",
            "67ea9ab32b974404a103db6c9dba81f7",
            "9659e596a06348b89ccff9b60c69ad51",
            "3f328fb7d053420d856fa922a971c181",
            "dd2fed86acd74711be3c6e08be0aa43a",
            "119fd8ebbc2b4db0811f2bd956571893",
            "087dae609055448dbb7011bb1166d431",
            "e4ce596e653a4fa69da08b5535217a1a",
            "e02970339d484862acd28cdb653f1262",
            "125083629b22437fae790b33184393bf"
          ]
        },
        "id": "L7lGYDO4EW97",
        "outputId": "e7940c39-bcba-4f05-d372-73cca7596b01"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f222dd520f3477e860dd200a27f9d02"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "49c87a1688dd46439880e95d43ca322c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "656ec4f582794c74a193c794d01e551e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3167370012.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0menc_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mXtr_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtr_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize_pairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0mXv_ids\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mXv_mask\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0myv\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtokenize_pairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mXt_ids\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mXt_mask\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0myt\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtokenize_pairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== CELL 6: Build tf.data.Dataset pipelines ====\n",
        "import tensorflow as tf\n",
        "\n",
        "def make_tf_dataset(input_ids, attn_mask, labels, batch_size=16, shuffle=False):\n",
        "    ds = tf.data.Dataset.from_tensor_slices((\n",
        "        {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attn_mask\n",
        "        },\n",
        "        labels\n",
        "    ))\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size=len(input_ids), seed=42)\n",
        "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "BATCH = 16  # default; will be overridden in experiments if needed\n",
        "\n",
        "train_ds = make_tf_dataset(Xtr_ids, Xtr_mask, ytr, batch_size=BATCH, shuffle=True)\n",
        "val_ds   = make_tf_dataset(Xv_ids,  Xv_mask,  yv,  batch_size=BATCH, shuffle=False)\n",
        "test_ds  = make_tf_dataset(Xt_ids,  Xt_mask,  yt,  batch_size=BATCH, shuffle=False)\n",
        "\n",
        "for batch in train_ds.take(1):\n",
        "    print(\"Batch keys:\", batch[0].keys(), \"input_ids shape:\", batch[0][\"input_ids\"].shape)\n"
      ],
      "metadata": {
        "id": "YvdxB48QEanO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== CELL 7: Build & compile the model (TensorFlow) ====\n",
        "from transformers import TFAutoModelForSeq2SeqLM\n",
        "import math\n",
        "\n",
        "# Load TF model\n",
        "tf.keras.backend.clear_session()\n",
        "model = TFAutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# Loss is automatically computed inside the model when 'labels' are present.\n",
        "# But Keras requires a compiled loss to show metrics. We pass a dummy loss;\n",
        "# the model will override it using internal seq2seq loss (cross-entropy).\n",
        "# We also track accuracy on the token-level (optional).\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-4)\n",
        "\n",
        "model.compile(optimizer=optimizer)  # internal loss used (labels -> teacher forcing)\n",
        "\n",
        "# Quick param count\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "u0cVN8r3EoYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== CELL 8: Simple evaluation helpers (BLEU, F1, Perplexity) ====\n",
        "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def generate_texts(model, tokenizer, inputs, max_new_tokens=32):\n",
        "    \"\"\"\n",
        "    Use model.generate to produce outputs for a batch of inputs.\n",
        "    Returns list of decoded strings.\n",
        "    \"\"\"\n",
        "    outputs = model.generate(\n",
        "        input_ids=inputs[\"input_ids\"],\n",
        "        attention_mask=inputs[\"attention_mask\"],\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        num_beams=4,\n",
        "        early_stopping=True\n",
        "    )\n",
        "    texts = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "    return texts\n",
        "\n",
        "def dataset_to_numpy_inputs(ds):\n",
        "    \"\"\"Collect a whole tf.data.Dataset into numpy arrays for generation.\"\"\"\n",
        "    all_input_ids = []\n",
        "    all_attention = []\n",
        "    all_labels    = []\n",
        "    for batch in ds:\n",
        "        X, Y = batch\n",
        "        all_input_ids.append(X[\"input_ids\"].numpy())\n",
        "        all_attention.append(X[\"attention_mask\"].numpy())\n",
        "        all_labels.append(Y.numpy())\n",
        "    return {\n",
        "        \"input_ids\": np.vstack(all_input_ids),\n",
        "        \"attention_mask\": np.vstack(all_attention)\n",
        "    }, np.vstack(all_labels)\n",
        "\n",
        "def decode_labels_to_text(labels_np, tokenizer):\n",
        "    \"\"\"Convert label ids (with -100 for padding) back to strings for metric calc.\"\"\"\n",
        "    # replace -100 (ignore index) back to pad_token_id for decoding\n",
        "    lab = labels_np.copy()\n",
        "    lab[lab == -100] = tokenizer.pad_token_id\n",
        "    texts = tokenizer.batch_decode(lab, skip_special_tokens=True)\n",
        "    return texts\n",
        "\n",
        "def compute_metrics(model, ds, tokenizer, label_texts=None):\n",
        "    \"\"\"\n",
        "    Compute BLEU, F1 (word-level, rough), and perplexity from average loss.\n",
        "    \"\"\"\n",
        "    # 1) Perplexity from loss over the dataset\n",
        "    losses = []\n",
        "    for X, Y in ds:\n",
        "        out = model(X, labels=Y, training=False)\n",
        "        # out.loss is mean cross-entropy for the batch\n",
        "        losses.append(float(out.loss.numpy()))\n",
        "    avg_loss = float(np.mean(losses))\n",
        "    ppl = math.exp(avg_loss)\n",
        "\n",
        "    # 2) Generate predictions\n",
        "    X_np, Y_np = dataset_to_numpy_inputs(ds)\n",
        "    pred_texts = generate_texts(model, tokenizer, X_np, max_new_tokens=32)\n",
        "    true_texts = decode_labels_to_text(Y_np, tokenizer)\n",
        "\n",
        "    # Prepare for BLEU\n",
        "    smoothie = SmoothingFunction().method4\n",
        "    refs = [[t.split()] for t in true_texts]   # list of reference lists\n",
        "    hyps = [p.split()] for p in pred_texts\n",
        "\n",
        "    bleu = corpus_bleu(refs, hyps, smoothing_function=smoothie)\n",
        "\n",
        "    # 3) Rough F1: we’ll compute token-level macro F1 on whitespace tokens (very rough)\n",
        "    # Build a vocabulary of tokens seen in references+pairs (for a simple mapping)\n",
        "    # For a simple “set overlap” style: label present token vs predicted present token\n",
        "    # (Not a perfect metric, but illustrates additional evaluation per rubric.)\n",
        "    from collections import Counter\n",
        "\n",
        "    def to_binary_bag(tokens, vocab):\n",
        "        c = Counter(tokens)\n",
        "        return np.array([1 if v in c else 0 for v in vocab], dtype=int)\n",
        "\n",
        "    # Build a small vocab from the validation set (limit size)\n",
        "    vocab = []\n",
        "    for t in true_texts:\n",
        "        for tok in t.split():\n",
        "            if tok not in vocab:\n",
        "                vocab.append(tok)\n",
        "            if len(vocab) > 2000:\n",
        "                break\n",
        "        if len(vocab) > 2000: break\n",
        "\n",
        "    y_true_bin, y_pred_bin = [], []\n",
        "    for t, p in zip(true_texts, pred_texts):\n",
        "        y_true_bin.append(to_binary_bag(t.split(), vocab))\n",
        "        y_pred_bin.append(to_binary_bag(p.split(), vocab))\n",
        "\n",
        "    if y_true_bin and y_pred_bin:\n",
        "        y_true_bin = np.vstack(y_true_bin)\n",
        "        y_pred_bin = np.vstack(y_pred_bin)\n",
        "        # Compute macro F1 across the token indicators\n",
        "        f1_macro = f1_score(y_true_bin, y_pred_bin, average=\"macro\", zero_division=0)\n",
        "    else:\n",
        "        f1_macro = 0.0\n",
        "\n",
        "    return {\n",
        "        \"avg_loss\": avg_loss,\n",
        "        \"perplexity\": ppl,\n",
        "        \"bleu\": bleu,\n",
        "        \"f1_macro_bow\": f1_macro,\n",
        "        \"samples\": list(zip(true_texts[:5], pred_texts[:5]))  # preview some pairs\n",
        "    }\n"
      ],
      "metadata": {
        "id": "3jx-rHJ3ErU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== CELL 9: Train once (baseline run) ====\n",
        "EPOCHS = 5\n",
        "BATCH  = 16  # used above; redefining for clarity\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2, restore_best_weights=True)\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Plot training curves (loss only; accuracy not meaningful for seq2seq)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history[\"loss\"], label=\"train\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"val\")\n",
        "plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.title(\"T5-small Fine-tuning Loss\")\n",
        "plt.legend(); plt.show()\n"
      ],
      "metadata": {
        "id": "JGKtYB6QEvKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== CELL 10: Baseline evaluation ====\n",
        "baseline_metrics_val  = compute_metrics(model, val_ds,  tokenizer)\n",
        "baseline_metrics_test = compute_metrics(model, test_ds, tokenizer)\n",
        "\n",
        "import pandas as pd\n",
        "pd.DataFrame([{\n",
        "    \"split\": \"val\",\n",
        "    \"avg_loss\": baseline_metrics_val[\"avg_loss\"],\n",
        "    \"perplexity\": baseline_metrics_val[\"perplexity\"],\n",
        "    \"BLEU\": baseline_metrics_val[\"bleu\"],\n",
        "    \"F1_macro(bag)\": baseline_metrics_val[\"f1_macro_bow\"]\n",
        "},{\n",
        "    \"split\": \"test\",\n",
        "    \"avg_loss\": baseline_metrics_test[\"avg_loss\"],\n",
        "    \"perplexity\": baseline_metrics_test[\"perplexity\"],\n",
        "    \"BLEU\": baseline_metrics_test[\"bleu\"],\n",
        "    \"F1_macro(bag)\": baseline_metrics_test[\"f1_macro_bow\"]\n",
        "}])\n"
      ],
      "metadata": {
        "id": "jsma34VFE1Kb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== CELL 11: Run 3 experiments and make a results table ====\n",
        "def reset_model(lr):\n",
        "    tf.keras.backend.clear_session()\n",
        "    m = TFAutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "    m.compile(optimizer=opt)\n",
        "    return m\n",
        "\n",
        "experiments = [\n",
        "    {\"name\": \"ExpA_baseline\", \"lr\": 2e-4, \"batch\": 16, \"epochs\": 4},\n",
        "    {\"name\": \"ExpB_higherLR\", \"lr\": 5e-4, \"batch\": 16, \"epochs\": 4},\n",
        "    {\"name\": \"ExpC_biggerBatch_lessEpochs\", \"lr\": 2e-4, \"batch\": 32, \"epochs\": 3},\n",
        "]\n",
        "\n",
        "rows = []\n",
        "for cfg in experiments:\n",
        "    print(f\"\\n🚀 Running {cfg['name']}  (lr={cfg['lr']}, batch={cfg['batch']}, epochs={cfg['epochs']})\")\n",
        "\n",
        "    # rebuild datasets if batch size changes\n",
        "    tr_ds = make_tf_dataset(Xtr_ids, Xtr_mask, ytr, batch_size=cfg[\"batch\"], shuffle=True)\n",
        "    v_ds  = make_tf_dataset(Xv_ids,  Xv_mask,  yv,  batch_size=cfg[\"batch\"], shuffle=False)\n",
        "    te_ds = make_tf_dataset(Xt_ids,  Xt_mask,  yt,  batch_size=cfg[\"batch\"], shuffle=False)\n",
        "\n",
        "    exp_model = reset_model(cfg[\"lr\"])\n",
        "    cb = [tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=1, restore_best_weights=True)]\n",
        "    h = exp_model.fit(tr_ds, validation_data=v_ds, epochs=cfg[\"epochs\"], callbacks=cb, verbose=1)\n",
        "\n",
        "    # Evaluate\n",
        "    m_val  = compute_metrics(exp_model, v_ds,  tokenizer)\n",
        "    m_test = compute_metrics(exp_model, te_ds, tokenizer)\n",
        "\n",
        "    rows.append({\n",
        "        \"Experiment\": cfg[\"name\"],\n",
        "        \"LR\": cfg[\"lr\"],\n",
        "        \"Batch\": cfg[\"batch\"],\n",
        "        \"Epochs\": cfg[\"epochs\"],\n",
        "        \"Val_Loss\": m_val[\"avg_loss\"],\n",
        "        \"Val_PPL\":  m_val[\"perplexity\"],\n",
        "        \"Val_BLEU\": m_val[\"bleu\"],\n",
        "        \"Val_F1\":   m_val[\"f1_macro_bow\"],\n",
        "        \"Test_Loss\": m_test[\"avg_loss\"],\n",
        "        \"Test_PPL\":  m_test[\"perplexity\"],\n",
        "        \"Test_BLEU\": m_test[\"bleu\"],\n",
        "        \"Test_F1\":   m_test[\"f1_macro_bow\"],\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(rows)\n",
        "results_df.sort_values(\"Test_BLEU\", ascending=False).reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "tFg2HO3pE4pP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== CELL 12: Simple interactive demo ====\n",
        "def answer(question, max_new_tokens=48):\n",
        "    # Prepare a single input\n",
        "    enc = tokenizer(\n",
        "        [f\"question: {question}\"],\n",
        "        padding=True, truncation=True, max_length=MAX_INPUT_LEN, return_tensors=\"tf\"\n",
        "    )\n",
        "    out = model.generate(\n",
        "        input_ids=enc[\"input_ids\"],\n",
        "        attention_mask=enc[\"attention_mask\"],\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        num_beams=4,\n",
        "        early_stopping=True\n",
        "    )\n",
        "    return tokenizer.decode(out[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"Try me:\")\n",
        "print(\"Q: How do I apply for admission?\")\n",
        "print(\"A:\", answer(\"How do I apply for admission?\"))\n"
      ],
      "metadata": {
        "id": "ePUAPlvfFBXs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}