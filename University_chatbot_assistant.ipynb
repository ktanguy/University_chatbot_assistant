{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMK6d8wUZLu7NNv1JYSInNv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2c3e2b7e2ec94f338a1f61a3bef44325": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e2f1f8d358a448f187a53b9289ee09cf",
              "IPY_MODEL_da187d2bf69448e59bcbca7e4e2d80e0",
              "IPY_MODEL_3f3a57547d054c35a237ad0848870ec9"
            ],
            "layout": "IPY_MODEL_a9a8f3844fcc4219a27bdaef7bada032"
          }
        },
        "e2f1f8d358a448f187a53b9289ee09cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_faf3b18bb96c45a2b65c7a351abd810a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e32662e220cd469fb794f86c8d5ad934",
            "value": "Fetchingâ€‡6â€‡files:â€‡100%"
          }
        },
        "da187d2bf69448e59bcbca7e4e2d80e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_484a363efb0f40848a3c8615fe607e0a",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_afcde48b6f70401e970200cf176bd5ba",
            "value": 6
          }
        },
        "3f3a57547d054c35a237ad0848870ec9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95ca0703112c453c97c6c018e3871ed2",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4d0406fda4814491ad1d8224f3510c73",
            "value": "â€‡6/6â€‡[00:00&lt;00:00,â€‡98.38it/s]"
          }
        },
        "a9a8f3844fcc4219a27bdaef7bada032": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faf3b18bb96c45a2b65c7a351abd810a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e32662e220cd469fb794f86c8d5ad934": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "484a363efb0f40848a3c8615fe607e0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afcde48b6f70401e970200cf176bd5ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "95ca0703112c453c97c6c018e3871ed2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d0406fda4814491ad1d8224f3510c73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ktanguy/University_chatbot_assistant/blob/main/University_chatbot_assistant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸŽ“ University Chatbot â€” FLAN-T5 (TensorFlow, Hugging Face, Gradio)\n",
        "\n",
        "This notebook fine-tunes **FLAN-T5 Small** on a **University FAQ** dataset (intents â†’ (user, bot) pairs), evaluates with **BLEU**, and provides a **Gradio** demo.\n",
        "\n",
        "**Fixes included:**\n",
        "- Proper `pad_token` fallback for T5\n",
        "- Masked loss (ignore padding via `-100`)\n",
        "- Deterministic seeds (Python / NumPy / TensorFlow)\n",
        "- sacrebleu reference shape\n",
        "- Optional GPU memory-growth for TF\n",
        "- Clean section ordering for â€œRun Allâ€\n",
        "\n",
        "> Update `INTENTS_PATH` in the Config cell if your file lives somewhere else in Drive.\n",
        "\n"
      ],
      "metadata": {
        "id": "EM0-VuHpwyk3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sacrebleu==2.4.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrGIIHtFyIBi",
        "outputId": "e323ec91-8b18-49ea-b545-a0dbd87fd1cd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.4/57.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q \"tensorflow==2.15.1\" \"keras==2.15.0\" \"transformers==4.41.2\" \"huggingface_hub==0.23.4\"\n",
        "print(\" Installed versions. Now go to Runtime > Restart runtime, then run the next cells.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvLitFHTEbEG",
        "outputId": "456693ac-8a1d-4b6a-9cbf-f84dc98fd68b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.15.1 (from versions: 2.16.0rc0, 2.16.1, 2.16.2, 2.17.0rc0, 2.17.0rc1, 2.17.0, 2.17.1, 2.18.0rc0, 2.18.0rc1, 2.18.0rc2, 2.18.0, 2.18.1, 2.19.0rc0, 2.19.0, 2.19.1, 2.20.0rc0, 2.20.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==2.15.1\u001b[0m\u001b[31m\n",
            "\u001b[0m Installed versions. Now go to Runtime > Restart runtime, then run the next cells.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If the runtime is fresh, run this once (takes a few minutes).\n",
        "!pip install -q transformers==4.42.0 tensorflow==2.13.0 accelerate==0.29.0 \\\n",
        "               gradio==4.0.0 datasets==2.18.0 evaluate==0.4.0 sacrebleu==2.4.0 \\\n",
        "               pandas numpy\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1tFZraRAJny",
        "outputId": "82ee17de-f72d-4ec1-e41d-63e25b31aeee"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.13.0 (from versions: 2.16.0rc0, 2.16.1, 2.16.2, 2.17.0rc0, 2.17.0rc1, 2.17.0, 2.17.1, 2.18.0rc0, 2.18.0rc1, 2.18.0rc2, 2.18.0, 2.18.1, 2.19.0rc0, 2.19.0, 2.19.1, 2.20.0rc0, 2.20.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==2.13.0\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: Use if your intents.json is in Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSETuMiYAV55",
        "outputId": "6b33d48f-0a86-48b7-99a9-c50acc7f26d0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, random, csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from transformers import AutoTokenizer, TFAutoModelForSeq2SeqLM\n",
        "import sacrebleu\n",
        "\n",
        "# Optional: soften GPU memory spikes\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "for g in gpus:\n",
        "    try:\n",
        "        tf.config.experimental.set_memory_growth(g, True)\n",
        "    except Exception as e:\n",
        "        print(\"GPU memory growth not set:\", e)\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnTrdydWxCo4",
        "outputId": "f5f7ee75-5ffd-40fa-c93b-76fda594353c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF version: 2.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Paths ===\n",
        "BASE_DIR = \"/content/university_chatbot_nb\"\n",
        "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
        "MODEL_DIR = os.path.join(BASE_DIR, \"models\", \"flan_t5_small_finetuned\")\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "# Prefer the merged dataset saved from your data-extraction notebook\n",
        "INTENTS_PATH = \"/content/drive/MyDrive/UniversityChatbot/intents_merged_tagged.json\"\n",
        "\n"
      ],
      "metadata": {
        "id": "qGgz3kHvrRLz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if not os.path.exists(INTENTS_PATH):\n",
        "    print(\"Merged dataset not found. Falling back to original intents.json\")\n",
        "    INTENTS_PATH = \"/content/drive/MyDrive/UniversityChatbot/intents_merged_tagged.json\"\n",
        "print(\"Using:\", INTENTS_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlT8XWLK-32F",
        "outputId": "1c9f2274-6c6c-48a6-cb19-3b8894d4c4f5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using: /content/drive/MyDrive/UniversityChatbot/intents_merged_tagged.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json\n",
        "\n",
        "print(\"Exists?\", os.path.exists(INTENTS_PATH), \"â†’\", INTENTS_PATH)\n",
        "\n",
        "with open(INTENTS_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "num_intents = len(data.get(\"intents\", []))\n",
        "num_texts   = sum(len(it.get(\"text\", [])) for it in data.get(\"intents\", []))\n",
        "print(f\"Intents: {num_intents} | Total user texts: {num_texts}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSFmgRxHBudY",
        "outputId": "ef2b49c9-6589-4b1c-b951-1c75b1f3cdfa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exists? True â†’ /content/drive/MyDrive/UniversityChatbot/intents_merged_tagged.json\n",
            "Intents: 39 | Total user texts: 412\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Expecting an intents.json in the common \"intents\" format:\n",
        "# {\"intents\": [{\"tag\":\"...\", \"text\":[\"u1\",\"u2\"], \"responses\":[\"r1\",\"r2\"]}, ...]}\n",
        "\n",
        "with open(INTENTS_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "    intents = json.load(f)\n",
        "\n",
        "pairs = []\n",
        "for intent in intents.get(\"intents\", []):\n",
        "    responses = intent.get(\"responses\", [])\n",
        "    texts     = intent.get(\"text\", [])\n",
        "    if not responses or not texts:\n",
        "        continue\n",
        "    # use the first response for supervised training (you can expand this later)\n",
        "    resp = str(responses[0]).strip()\n",
        "    for t in texts:\n",
        "        t_clean = str(t).strip()\n",
        "        if t_clean and resp:\n",
        "            pairs.append((t_clean, resp))\n",
        "\n",
        "# Train / test split (80/20)\n",
        "random.shuffle(pairs)\n",
        "split = int(0.8 * len(pairs))\n",
        "train_pairs = pairs[:split]\n",
        "test_pairs  = pairs[split:]\n",
        "\n",
        "train_csv = os.path.join(DATA_DIR, \"train.csv\")\n",
        "test_csv  = os.path.join(DATA_DIR, \"test.csv\")\n",
        "\n",
        "with open(train_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "    w = csv.writer(f); w.writerow([\"user\", \"bot\"]); w.writerows(train_pairs)\n",
        "with open(test_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "    w = csv.writer(f); w.writerow([\"user\", \"bot\"]); w.writerows(test_pairs)\n",
        "\n",
        "print(f\"Total pairs: {len(pairs)} | Train: {len(train_pairs)} | Test: {len(test_pairs)}\")\n",
        "print(\"Train CSV:\", train_csv)\n",
        "print(\"Test  CSV:\", test_csv)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEnWfsNrzFe0",
        "outputId": "f80e3bcc-1c62-4aee-ca47-27478c08e77a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total pairs: 412 | Train: 329 | Test: 83\n",
            "Train CSV: /content/university_chatbot_nb/data/train.csv\n",
            "Test  CSV: /content/university_chatbot_nb/data/test.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re, html\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "TRAIN = \"/content/university_chatbot_nb/data/train.csv\"\n",
        "TEST  = \"/content/university_chatbot_nb/data/test.csv\"\n",
        "\n",
        "# --- ALU knowledge snippets (succinct, safe, no HTML) ---\n",
        "ALU_KB = {\n",
        "    \"admission\":  \"Admissions are subject to change. Please check the official ALU Admissions page for the most current requirements and deadlines.\",\n",
        "    \"fees\":       \"Tuition varies by programme and year. Check the Student Portal > Finance for current fees and payment instructions.\",\n",
        "    \"installment\":\"Installment options may be available. See Student Finance on the Student Portal for approved plans.\",\n",
        "    \"scholarship\":\"Scholarships and financial aid may be available. Review the Scholarships/Financial Aid section on the admissions or finance pages.\",\n",
        "    \"hostel\":     \"Limited on-campus or partner housing may be available. Contact Student Services for current availability, rates, and application steps.\",\n",
        "    \"address\":    \"ALU Kigali is located at Bumbogo Innovation City, Gasabo, Kigali. Refer to the official site for directions.\",\n",
        "    \"calendar\":   \"See the Academic Calendar on the Student Portal for term dates, add/drop windows, and exams.\",\n",
        "    \"timetable\":  \"Class schedules are published each term. Check your timetable on the Student Portal.\",\n",
        "    \"exam\":       \"Exam schedules are listed on the Academic Calendar and communicated via the Student Portal.\",\n",
        "    \"programme\":  \"See the Programmes page for current offerings, entry requirements, and learning modes.\",\n",
        "    \"library\":    \"Students have access to digital resources and on-site study spaces. Use your student credentials to access the library portal.\",\n",
        "    \"canteen\":    \"On-campus food options are available; offerings and hours may vary by term. Check campus notices or Student Services.\",\n",
        "    \"contact\":    \"Use the Student Portal or the Contact page for official emails and support channels.\",\n",
        "    \"careers\":    \"Career Services supports internships and job readiness. Visit the Careers page or portal to get started.\",\n",
        "    \"general\":    \"Please check the Student Portal or contact Student Services for the latest official information.\"\n",
        "}\n",
        "\n",
        "# --- Keyword routing for replacements (ordered by specificity -> general) ---\n",
        "ROUTES = [\n",
        "    (\"installment\",  [\"installment\",\"installments\",\"instalment\",\"instalments\",\"payment plan\"]),\n",
        "    (\"scholarship\",  [\"scholarship\",\"financial aid\",\"bursary\",\"aid\",\"funding\"]),\n",
        "    (\"fees\",         [\"fee\",\"fees\",\"tuition\",\"invoice\",\"payment\",\"pay\",\"bank\",\"card\",\"tuition cost\",\"costs\"]),\n",
        "    (\"hostel\",       [\"hostel\",\"housing\",\"accommodation\",\"residence\",\"dorm\"]),\n",
        "    (\"address\",      [\"address\",\"location\",\"where is\",\"direction\",\"map\",\"campus\"]),\n",
        "    (\"calendar\",     [\"calendar\",\"academic calendar\"]),\n",
        "    (\"timetable\",    [\"timetable\",\"schedule\",\"class time\",\"class schedule\",\"time table\"]),\n",
        "    (\"exam\",         [\"exam\",\"examination\",\"midterm\",\"final\",\"assessment\",\"tests\"]),\n",
        "    (\"programme\",    [\"programme\",\"program\",\"course\",\"degree\",\"major\",\"specialization\",\"track\"]),\n",
        "    (\"library\",      [\"library\",\"ebook\",\"e-book\",\"database\",\"journal\",\"catalog\",\"catalogue\"]),\n",
        "    (\"canteen\",      [\"canteen\",\"cafeteria\",\"food\",\"menu\",\"dining\"]),\n",
        "    (\"contact\",      [\"contact\",\"email\",\"phone\",\"helpdesk\",\"support\",\"whatsapp\"]),\n",
        "    (\"careers\",      [\"career\",\"internship\",\"jobs\",\"employer\",\"placement\"]),\n",
        "    (\"admission\",    [\"admission\",\"admissions\",\"apply\",\"application\",\"offer\",\"enroll\",\"enrol\",\"join\"]),\n",
        "]\n",
        "\n",
        "# --- Placeholder/HTML cleanup rules ---\n",
        "TAG_RE = re.compile(r\"<[^>]+>\")\n",
        "PLACEHOLDER_PATTERNS = [\n",
        "    r\"ADD\\s+YOUR.*\",\n",
        "    r\"ADD\\s+YOU\\s+OWN\\s+ANSWERS.*\",\n",
        "    r\"ADD\\s+YOU\\s+GOOGLE\\s+MAP.*\",\n",
        "    r\"CLICK\\s+HERE.*\",\n",
        "    r\"\\bhere\\b\\s*$\",                # bare 'here' ending\n",
        "    r\"visit\\s+.*(link|site|page).*\",# vague link directives\n",
        "]\n",
        "JUNK_SNIPPETS = [\n",
        "    \"target=\\\"_blank\\\"\", \"href=\", \"</a>\", \"<a\", \"http://\", \"https://\"\n",
        "]\n",
        "\n",
        "# answers that are too generic to be useful\n",
        "GENERIC_RESP_PATTERNS = [\n",
        "    r\"visit the (official )?(site|page)\",\n",
        "    r\"for more (info|information).*\",\n",
        "    r\"contact us.*\",\n",
        "    r\"refer to.*\",\n",
        "    r\"see above.*\",\n",
        "]\n",
        "\n",
        "def looks_placeholder(text: str) -> bool:\n",
        "    if not text or str(text).strip() == \"\":\n",
        "        return True\n",
        "    T = str(text)\n",
        "    # any HTML tag?\n",
        "    if TAG_RE.search(T): return True\n",
        "    # obvious placeholders\n",
        "    for p in PLACEHOLDER_PATTERNS:\n",
        "        if re.search(p, T, flags=re.IGNORECASE):\n",
        "            return True\n",
        "    # anchor/link artifacts without meaningful content\n",
        "    if any(s in T for s in JUNK_SNIPPETS):\n",
        "        return True\n",
        "    # too short / non-informative\n",
        "    if len(T.strip()) < 12:\n",
        "        return True\n",
        "    # generic boilerplate\n",
        "    for p in GENERIC_RESP_PATTERNS:\n",
        "        if re.search(p, T, flags=re.IGNORECASE):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def normalize_text(s: str) -> str:\n",
        "    s = html.unescape(str(s or \"\"))\n",
        "    s = TAG_RE.sub(\"\", s)                         # strip HTML\n",
        "    s = re.sub(r\"\\s{2,}\", \" \", s)                 # collapse spaces\n",
        "    s = re.sub(r\"[ \\t]*\\n+[ \\t]*\", \" \", s)        # collapse newlines\n",
        "    s = re.sub(r\"\\s*([?!.,;:])\\s*\", r\"\\1 \", s)    # tidy punctuation spacing\n",
        "    s = re.sub(r\"[!?]{3,}\", \"!!\", s)              # limit punctuation runs\n",
        "    s = s.strip()\n",
        "    return s\n",
        "\n",
        "def route_to_kb(user: str) -> str:\n",
        "    u = (user or \"\").lower()\n",
        "    for key, kws in ROUTES:\n",
        "        if any(kw in u for kw in kws):\n",
        "            return ALU_KB[key]\n",
        "    return ALU_KB[\"general\"]\n",
        "\n",
        "def clean_answer(user: str, bot: str, stats: Counter) -> str:\n",
        "    raw = str(bot or \"\")\n",
        "    # quick remove obvious placeholder phrases (pre-normalization)\n",
        "    for p in PLACEHOLDER_PATTERNS:\n",
        "        raw = re.sub(p, \"\", raw, flags=re.IGNORECASE)\n",
        "    raw = normalize_text(raw)\n",
        "\n",
        "    # if after normalization it's weak, route to KB\n",
        "    if looks_placeholder(raw):\n",
        "        routed = route_to_kb(user)\n",
        "        stats[\"replaced_with_kb\"] += 1\n",
        "        # track which bucket we used\n",
        "        bucket_used = next((k for k, kws in ROUTES if any(kw in (user or \"\").lower() for kw in kws)), \"general\")\n",
        "        stats[f\"kb_{bucket_used}\"] += 1\n",
        "        return routed\n",
        "\n",
        "    return raw\n",
        "\n",
        "def clean_file(path, preview_path=None):\n",
        "    df = pd.read_csv(path).dropna()\n",
        "    before = len(df)\n",
        "    stats = Counter()\n",
        "\n",
        "    # 1) dedupe exact pairs\n",
        "    df = df.drop_duplicates(subset=[\"user\",\"bot\"]).reset_index(drop=True)\n",
        "\n",
        "    # 2) clean/route\n",
        "    df[\"bot\"] = [clean_answer(u, b, stats) for u, b in zip(df[\"user\"], df[\"bot\"])]\n",
        "\n",
        "    # 3) drop rows that are still empty (very unlikely now)\n",
        "    df = df[df[\"bot\"].astype(str).str.strip() != \"\"].reset_index(drop=True)\n",
        "    after = len(df)\n",
        "    df.to_csv(path, index=False)\n",
        "\n",
        "    # small preview for debugging/report\n",
        "    if preview_path:\n",
        "        df.sample(min(10, len(df))).to_csv(preview_path, index=False)\n",
        "\n",
        "    print(f\"Cleaned {path}: {before} -> {after}\")\n",
        "    print(\"Replacements:\", stats[\"replaced_with_kb\"])\n",
        "    # print top buckets used\n",
        "    for k, v in sorted(stats.items()):\n",
        "        if k.startswith(\"kb_\"):\n",
        "            print(f\"  {k}: {v}\")\n",
        "\n",
        "# Run cleaning + save previews\n",
        "clean_file(TRAIN, preview_path=\"/content/university_chatbot_nb/data/train_clean_preview.csv\")\n",
        "clean_file(TEST,  preview_path=\"/content/university_chatbot_nb/data/test_clean_preview.csv\")\n",
        "\n",
        "print(\"\\nCleaned train sample:\")\n",
        "print(pd.read_csv(\"/content/university_chatbot_nb/data/train_clean_preview.csv\").head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGgViUWvH-Xw",
        "outputId": "dd0e3bc9-cead-46db-d315-d1b3355817e1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned /content/university_chatbot_nb/data/train.csv: 324 -> 322\n",
            "Replacements: 17\n",
            "  kb_address: 10\n",
            "  kb_general: 7\n",
            "Cleaned /content/university_chatbot_nb/data/test.csv: 83 -> 83\n",
            "Replacements: 4\n",
            "  kb_address: 1\n",
            "  kb_general: 3\n",
            "\n",
            "Cleaned train sample:\n",
            "                                            user                                                bot\n",
            "0  courses offered in (your univrsity(UNI) name)  Our university offers Information Technology, ...\n",
            "1                                    hostel fees  Tuition varies by programme and year. Check th...\n",
            "2                                        address  ALU Kigali is located at Bumbogo Innovation Ci...\n",
            "3                               name of extc hod  Different school wise hod are different. So be...\n",
            "4                                     how are ya  Please check the Student Portal or contact Stu...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv(\"/content/university_chatbot_nb/data/train.csv\")\n",
        "test_df  = pd.read_csv(\"/content/university_chatbot_nb/data/test.csv\")\n",
        "\n",
        "print(\"Train sample:\")\n",
        "print(train_df.sample(min(5, len(train_df))))\n",
        "\n",
        "print(\"\\nTest sample:\")\n",
        "print(test_df.sample(min(5, len(test_df))))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HdAgAlrG6pT",
        "outputId": "bd407cdf-823f-452b-c153-aab4a6f6a85a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train sample:\n",
            "                            user                                                bot\n",
            "196  Does college provide hostel  Limited on-campus or partner housing may be av...\n",
            "299               seat allotment  For IT, Computer and extc 60 per branch and se...\n",
            "228               principal name  XYZ is college principal and if you need any h...\n",
            "227                         exam              Here is the Academic Calendar website\n",
            "134     Is scholarship available  Scholarships and financial aid may be availabl...\n",
            "\n",
            "Test sample:\n",
            "                                   user                                                bot\n",
            "15                            more info                         You can contact at: NUMBER\n",
            "52                              shut up                    please use appropriate language\n",
            "63                 how much is the fees  Tuition varies by programme and year. Check th...\n",
            "72  what is the name of your developers                                   College students\n",
            "30                             dumb ass                    please use appropriate language\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Model & Training Hyperparams ===\n",
        "MODEL_NAME = \"google/flan-t5-small\"   # or another model if you prefer\n",
        "MAX_LEN    = 128\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS     = 5\n",
        "LR         = 5e-5\n",
        "SEED       = 42\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "print(\"Model name:\", MODEL_NAME)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5t4PmqfIffW",
        "outputId": "101be76e-590f-4837-a914-24eb99bc1a11"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model name: google/flan-t5-small\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upgrade Torch to a safe version (>=2.6). Use CPU wheels to avoid CUDA conflicts.\n",
        "!pip install -q --upgrade torch==2.8.0+cpu torchvision==0.23.0+cpu torchaudio==2.8.0+cpu \\\n",
        "  -f https://download.pytorch.org/whl/cpu/torch_stable.html\n",
        "\n",
        "import torch\n",
        "print(\"Torch version:\", torch.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5NLCkniNBoF",
        "outputId": "c2c7090a-f2b2-46a9-b603-c1ed478b3c64"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==2.8.0+cpu (from versions: 2.2.0, 2.2.0+cpu, 2.2.1, 2.2.1+cpu, 2.2.2, 2.2.2+cpu, 2.3.0, 2.3.0+cpu, 2.3.1, 2.3.1+cpu, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0, 2.7.1, 2.8.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==2.8.0+cpu\u001b[0m\u001b[31m\n",
            "\u001b[0mTorch version: 2.8.0+cu126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity check: youâ€™re already on a safe Torch version (>=2.6)\n",
        "import torch, transformers\n",
        "print(\"Torch:\", torch.__version__)\n",
        "print(\"Transformers:\", transformers.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bs-jbrSpPOH4",
        "outputId": "bcd0edd4-1d92-431e-d6d7-3869898682ed"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch: 2.8.0+cu126\n",
            "Transformers: 4.57.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import snapshot_download\n",
        "from transformers import AutoTokenizer, TFAutoModelForSeq2SeqLM\n",
        "\n",
        "# Download ONLY TF files for t5-small so we avoid any PT files entirely\n",
        "local_repo = snapshot_download(\n",
        "    repo_id=\"t5-small\",\n",
        "    allow_patterns=[\"tokenizer.json\",\"spiece.model\",\"*.json\",\"tf_model.h5\"]\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(local_repo)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Load native TensorFlow weights (no extra flags needed)\n",
        "model = TFAutoModelForSeq2SeqLM.from_pretrained(local_repo)\n",
        "\n",
        "print(\" Loaded t5-small with native TF weights.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "2c3e2b7e2ec94f338a1f61a3bef44325",
            "e2f1f8d358a448f187a53b9289ee09cf",
            "da187d2bf69448e59bcbca7e4e2d80e0",
            "3f3a57547d054c35a237ad0848870ec9",
            "a9a8f3844fcc4219a27bdaef7bada032",
            "faf3b18bb96c45a2b65c7a351abd810a",
            "e32662e220cd469fb794f86c8d5ad934",
            "484a363efb0f40848a3c8615fe607e0a",
            "afcde48b6f70401e970200cf176bd5ba",
            "95ca0703112c453c97c6c018e3871ed2",
            "4d0406fda4814491ad1d8224f3510c73"
          ]
        },
        "id": "W48v42duEqNe",
        "outputId": "a90038a7-9eb6-4f21-dec8-0eb50a9d5d5e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c3e2b7e2ec94f338a1f61a3bef44325"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at /root/.cache/huggingface/hub/models--t5-small/snapshots/df1b051c49625cf57a3d0d8d3863ed4d13564fe4.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Loaded t5-small with native TF weights.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, pandas as pd, tensorflow as tf\n",
        "\n",
        "MAX_LEN    = 128\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "def load_pairs_csv(path):\n",
        "    df = pd.read_csv(path).dropna().astype(str)\n",
        "    return df[\"user\"].tolist(), df[\"bot\"].tolist()\n",
        "\n",
        "def make_tf_dataset(tokenizer, sources, targets, max_len=128, batch_size=8):\n",
        "    enc = tokenizer(sources, truncation=True, padding=\"max_length\",\n",
        "                    max_length=max_len, return_tensors=\"np\")\n",
        "    dec = tokenizer(targets, truncation=True, padding=\"max_length\",\n",
        "                    max_length=max_len, return_tensors=\"np\")\n",
        "\n",
        "    features = {\n",
        "        \"input_ids\": enc[\"input_ids\"],\n",
        "        \"attention_mask\": enc[\"attention_mask\"],\n",
        "        \"labels\": np.where(dec[\"input_ids\"] == tokenizer.pad_token_id, -100, dec[\"input_ids\"]),\n",
        "    }\n",
        "    ds = tf.data.Dataset.from_tensor_slices(features)\n",
        "    return ds.shuffle(len(sources)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_src, train_tgt = load_pairs_csv(\"/content/university_chatbot_nb/data/train.csv\")\n",
        "val_src,   val_tgt   = load_pairs_csv(\"/content/university_chatbot_nb/data/test.csv\")\n",
        "\n",
        "train_ds = make_tf_dataset(tokenizer, train_src, train_tgt, max_len=MAX_LEN, batch_size=BATCH_SIZE)\n",
        "val_ds   = make_tf_dataset(tokenizer, val_src,   val_tgt,   max_len=MAX_LEN, batch_size=BATCH_SIZE)\n",
        "\n",
        "len(train_src), len(val_src)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwJtLOORkLin",
        "outputId": "3dc36adf-382d-4824-87cb-5eb81f725b11"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(322, 83)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LR = 5e-5\n",
        "EPOCHS = 5\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=LR)\n",
        "model.compile(optimizer=optimizer)  # HF computes masked loss because \"labels\" exist\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2, restore_best_weights=True),\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"/content/university_chatbot_nb/models/t5_small_finetuned/ckpt\",\n",
        "        save_weights_only=True, save_best_only=True, monitor=\"val_loss\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "history = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, callbacks=callbacks)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAY6uo6llMgr",
        "outputId": "48e266d5-bba8-43d6-de99-61093088deb9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "41/41 [==============================] - 649s 14s/step - loss: 6.1701 - val_loss: 4.8000\n",
            "Epoch 2/5\n",
            "41/41 [==============================] - 550s 13s/step - loss: 4.9012 - val_loss: 4.1680\n",
            "Epoch 3/5\n",
            "41/41 [==============================] - 538s 13s/step - loss: 4.3552 - val_loss: 3.6967\n",
            "Epoch 4/5\n",
            "41/41 [==============================] - 563s 14s/step - loss: 3.8963 - val_loss: 3.3064\n",
            "Epoch 5/5\n",
            "41/41 [==============================] - 535s 13s/step - loss: 3.4672 - val_loss: 2.9628\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, re, sacrebleu\n",
        "\n",
        "MODEL_DIR = \"/content/university_chatbot_nb/models/t5_small_finetuned\"\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "model.save_pretrained(MODEL_DIR)\n",
        "tokenizer.save_pretrained(MODEL_DIR)\n",
        "with open(os.path.join(MODEL_DIR, \"history.json\"), \"w\") as f:\n",
        "    json.dump({k: [float(x) for x in v] for k, v in (history.history or {}).items()}, f, indent=2)\n",
        "\n",
        "# Clean decoded outputs\n",
        "TAG_RE = re.compile(r\"<[^>]+>\")\n",
        "BAD = [\"ADD YOUR\",\"ADD YOU OWN ANSWERS\",\"target=\\\"_blank\\\"\",\"href=\",\"</a>\",\"<a\"]\n",
        "def clean_answer(text: str) -> str:\n",
        "    s = TAG_RE.sub(\"\", str(text))\n",
        "    for b in BAD: s = s.replace(b, \"\")\n",
        "    return re.sub(r\"\\s{2,}\", \" \", s).strip()\n",
        "\n",
        "def generate_response(prompt, max_len=128):\n",
        "    out = model.generate(**tokenizer(prompt, return_tensors=\"tf\", truncation=True, max_length=max_len))\n",
        "    return clean_answer(tokenizer.decode(out[0], skip_special_tokens=True))\n",
        "\n",
        "# BLEU on test\n",
        "import pandas as pd\n",
        "df_val = pd.read_csv(\"/content/university_chatbot_nb/data/test.csv\").dropna().astype(str)\n",
        "preds = [generate_response(q) for q in df_val[\"user\"]]\n",
        "refs  = df_val[\"bot\"].tolist()\n",
        "bleu  = sacrebleu.corpus_bleu(preds, [refs])\n",
        "print(f\"BLEU: {bleu.score:.2f}\")\n",
        "\n",
        "# Peek a few predictions\n",
        "pd.DataFrame({\"user\": df_val[\"user\"], \"ref\": refs, \"pred\": preds}).sample(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "uYQPq9ZwloKu",
        "outputId": "36918828-7b00-4d16-fa47-df7c25b9b730"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/generation/tf_utils.py:836: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length.  recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU: 0.36\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                              user  ...                                               pred\n",
              "30                        dumb ass  ...   I'm not sure I'm going to be a fan of this post.\n",
              "0                       I love you  ...                        I love you and your family!\n",
              "22  number of seats in each branch  ...  The University of New York has a number of bra...\n",
              "31                    holiday list  ...  Check out the official website for the latest ...\n",
              "18               Sports activities  ...  Sport activities include sports activities, sp...\n",
              "\n",
              "[5 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a5a58a69-1710-4085-8d7c-cf39d1d85172\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>ref</th>\n",
              "      <th>pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>dumb ass</td>\n",
              "      <td>please use appropriate language</td>\n",
              "      <td>I'm not sure I'm going to be a fan of this post.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I love you</td>\n",
              "      <td>I am not program for this, please ask appropri...</td>\n",
              "      <td>I love you and your family!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>number of seats in each branch</td>\n",
              "      <td>For IT, Computer and extc 60 per branch and se...</td>\n",
              "      <td>The University of New York has a number of bra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>holiday list</td>\n",
              "      <td>Academic calender is given to you by your clas...</td>\n",
              "      <td>Check out the official website for the latest ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Sports activities</td>\n",
              "      <td>Our university encourages all-round developmen...</td>\n",
              "      <td>Sport activities include sports activities, sp...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a5a58a69-1710-4085-8d7c-cf39d1d85172')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a5a58a69-1710-4085-8d7c-cf39d1d85172 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a5a58a69-1710-4085-8d7c-cf39d1d85172');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-39c2e928-f43b-46aa-a876-c51a920ae006\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-39c2e928-f43b-46aa-a876-c51a920ae006')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-39c2e928-f43b-46aa-a876-c51a920ae006 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"user\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"I love you\",\n          \"Sports activities\",\n          \"number of seats in each branch\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ref\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"I am not program for this, please ask appropriate query\",\n          \"Our university encourages all-round development of students and hence provides sports facilities in the campus. For more details visithere\",\n          \"For IT, Computer and extc 60 per branch and seat may be differ for different department.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"I love you and your family!\",\n          \"Sport activities include sports activities, sports activities, sports activities, sports activities, sports activities, sports\",\n          \"The University of New York has a number of branches and is available for the public.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def respond(user_input):\n",
        "    text = user_input.strip()\n",
        "    if len(text) < 2:\n",
        "        return \"Please ask a full question related to university information.\"\n",
        "    return generate_response(text, max_len=MAX_LEN)\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=respond,\n",
        "    inputs=\"text\",\n",
        "    outputs=\"text\",\n",
        "    title=\"ðŸŽ“ University Chatbot (t5-small)\",\n",
        "    description=(\n",
        "        \"Ask about admissions, fees, accommodation/hostels, programmes, timetable, \"\n",
        "        \"library, or contacts. Developed by Tanguy Kwizera for ALU.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# ðŸš€ Launch with public link\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "RZSANb3erE-S",
        "outputId": "7db22922-d7ea-459f-a27a-f323e375c969"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://748ddf784fe2a213ae.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://748ddf784fe2a213ae.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ]
}